{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\"  if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convblock1 = nn.Sequential(\n",
    "                nn.Conv2d(3,8,2,stride=2),\n",
    "                nn.ReLU(False)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.convblock2 = nn.Sequential(\n",
    "                nn.Conv2d(8,16,2,stride=2),\n",
    "#                 nn.MaxPool2d(2,2),\n",
    "                nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.convblock3 = nn.Sequential(\n",
    "                nn.Conv2d(16,32,2,stride=2),\n",
    "                nn.MaxPool2d(2,2),\n",
    "                nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.convblock1(x)\n",
    "        print(\"v1\",x.shape)\n",
    "        x = self.convblock2(x)\n",
    "        print(\"v2\",x.shape)\n",
    "        x = self.convblock3(x)\n",
    "        print(\"v3\",x.shape)\n",
    "        flatten = x.view(2*2*32,-1)\n",
    "        return x,flatten\n",
    "\n",
    "model = Network().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 2, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.convblock1[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,3,32,32),dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 torch.Size([1, 8, 16, 16])\n",
      "v2 torch.Size([1, 16, 8, 8])\n",
      "v3 torch.Size([1, 32, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x,flatten = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Sequential):\n",
    "    def __init__(self, in_filters, out_filters, bn=True, kernel_size=3, stride=2):\n",
    "        layers = [nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride=stride)]\n",
    "        if bn:\n",
    "            layers.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(3,8,kernel_size=2,stride=2)\n",
    "        self.conv2 = ConvBlock(8,16,kernel_size=2,stride=2)\n",
    "        self.conv3 = ConvBlock(16,32,kernel_size=2,stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,3,32,32),dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 4, 4])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,3,32,32),dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = F.pad(x,(1,1,2,2))\n",
    "# Examples::\n",
    "\n",
    "#     >>> t4d = torch.empty(3, 3, 4, 2)\n",
    "#     >>> p1d = (1, 1) # pad last dim by 1 on each side\n",
    "#     >>> out = F.pad(t4d, p1d, \"constant\", 0)  # effectively zero padding\n",
    "#     >>> print(out.data.size())\n",
    "#     torch.Size([3, 3, 4, 4])\n",
    "#     >>> p2d = (1, 1, 2, 2) # pad last dim by (1, 1) and 2nd to last by (2, 2)\n",
    "#     >>> out = F.pad(t4d, p2d, \"constant\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 36, 34])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
